{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M78OMf4okn3"
      },
      "source": [
        "# **Tutorial on Record Selection**\n",
        "## METIS Summer School Pavia 2022\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# Getting started\n",
        "This will install the requirements for record selection, openquake, etc...\n",
        "Only execute if necessary, otherwise skip to the directories definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UHBKpp1Zaug"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#pip uninstall --yes numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzgMntf6Ze3c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# pip install --pre numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RZMUVPhW_6g"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# pip install openquake.engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW_tte1bZ02O"
      },
      "source": [
        "Next step is to identify the directories for the various inputs, coming from ***PSHA*** and ***disaggregation***, the ground motion ***DB*** metadata and the ***outputs***. \n",
        "\n",
        "It is important to keep only disaggregation for 1 location `M_R_eps file`, since record selection will be done just for 1 site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK7JTsm84iUs"
      },
      "outputs": [],
      "source": [
        "# These are created within the machine \n",
        "out_dir= r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\output\" # directory for outputs\n",
        "fig_dir = r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\output\\figures\"  # directory where the figures are stored\n",
        "output_dir = r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\output\\outputGM\"  # directory where ground motion outputs are stored\n",
        "# These will come from github\n",
        "mat_dir = r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\Data\\DB_final_6.mat\"  # mat file with the Database of records - metadata flatfile\n",
        "path_dis = r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\Data\\PSHA_Output\\Disaggregation\"  # output from OQ\n",
        "path_haz = r\"C:\\Users\\Pablo\\Documents\\PhD\\Other\\Zagreb\\GMSelection\\Data\\PSHA_Output\\Hazard\"  # output from OQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Umk3RBwWsd"
      },
      "source": [
        "# ESM Database\n",
        "In order to select records, we require a database to pull them from, it is important that it contains relevant information on the causative parameters as well as the intensities of the event. Here, the mat file contains all the relevant information about the records, such as spectral quantities, Magnitude, distance to station, depth, Vs30, etc.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLMLBflhYMGO"
      },
      "source": [
        "Loading the functions and packages and creating directories... \n",
        "\n",
        "**Be mindful to change to the directory where the other functions are!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RT9SUupbxCd",
        "outputId": "160138fe-c6f3-4535-e89d-bdacceb14f29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "from os import path\n",
        "import math\n",
        "\n",
        "if path.exists(out_dir) == False:\n",
        "  os.mkdir(out_dir)\n",
        "if path.exists(output_dir) == False:\n",
        "  os.mkdir(output_dir)\n",
        "if path.exists(fig_dir) == False:\n",
        "  os.mkdir(fig_dir)\n",
        "if path.exists(output_dir) == False:\n",
        "  os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(r\"D:\\Documents\\PhD\\METIS\\Summer_school\\Summer_school\\to share\")\n",
        "import numpy as np\n",
        "from utils_bsc import CS\n",
        "from time import time\n",
        "from OQProc2 import disagg_MReps, hazard\n",
        "import os\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "from Saveutils import fxn, saveMat, plot_select_recs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MKd4kLU7mkQK"
      },
      "source": [
        "# Conditional spectrum \n",
        "The conditional spectrum, as previously stated is a target based record selection procedure which accounts for the variability in the hazard. \n",
        "The steps mainly followed by this procedure which will be detailed through the next steps are:\n",
        "  1. Definition of target periods, intensities, GM, limits, etc.\n",
        "  2. Disaggregation of the hazard for a given period ***T*** and a given ***probability of exceedance*** (or RP).\n",
        "  3. Definition of the target spectrum, mean and variance.\n",
        "  4. Ground motion selection through sampling.\n",
        "  5. Optimization.\n",
        "\n",
        "## The algorithm\n",
        "\n",
        "Script used to select the records based on the Sa(T*) value. It is based (with some modifications) on: https://github.com/volkanozsarac/EzGM.git;\n",
        "\n",
        "Calculation of SSEs is from \"A Computationally Efficient Ground-Motion Selection Algorithm for Matching a Target Response\n",
        "    Spectrum Mean and Variance\" Jayaram, 2011:  https://journals.sagepub.com/doi/pdf/10.1193/1.3608002;\n",
        "\n",
        "Any GMPE available in the OQ library can be used. If we set pinfo=1 we will get information about GMPE (e.g. for which\n",
        "    IM it was derived)\n",
        "make sure that you use same GMPE in hazard calculation (in OQ) and for the selection\n",
        "\n",
        "Main processes about CS are found in the `utils_bsc` script, we will see some parts of the code within here as we execute the commands...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIK0FvZ2BAxa"
      },
      "source": [
        "# Main Inputs\n",
        "\n",
        "Now we set the inputs: level of intensity, number of records to select,Vs30 and scaling limits, etc.\n",
        "\n",
        "Additionally we define the inputs for the GMPE to be used for the target spectrum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8eZixyxco16"
      },
      "outputs": [],
      "source": [
        "poes = [0.1, 0.05]  # probability of exceedance in 50 years\n",
        "T_target = [0.075, 0.10, 0.15, 0.20, 0.25, 0.30, 0.40, 0.50, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.50, 1.6,\n",
        "            1.7, 1.8, 1.9, 2.00, 3.00, 4.00]  # periods of interest for target spectrum\n",
        "\n",
        "nIM = 2     # IML for calculation (out of the list of poes)\n",
        "T_star = 0.2  # period of interest\n",
        "Mbin = 1.0  # the values used in hazard calculation (OQ)\n",
        "dbin = 10   # the values used in hazard calculation (OQ)\n",
        "nGM = 40      # number of GM to select\n",
        "Vs30_lims=[600,2500] # Vs30 limits in m/s\n",
        "maxSF =  4.0  # max scaling factor\n",
        "minSF = 0.2 # min scaling factor\n",
        "\n",
        "\n",
        "# Input for the GMPE (depends on the GMPE)\n",
        "rake = 180\n",
        "Vs30 = 800\n",
        "Fhw = 1\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CcqUja4-mtMP"
      },
      "source": [
        "# Disaggregation analysis\n",
        "In order to create a target spectrum, it is necessary to understand which events will have the most contribution to the hazard, this will allow us to get the target scenario\"s causative parameters:\n",
        " Magnitude (***M***), Distance (***R***) and ***$\\epsilon$***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "OYOeyb4ZmUom",
        "outputId": "5b0d1ee0-cf16-4a3b-adb9-d52095a7770e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read the results of the disaggregation and get M, R and epsilon values\n",
        "imls = hazard(poes, path_haz, output_dir=fig_dir,\n",
        "              rlz=\"hazard_curve-mean\", i_save=1, i_show=1)  # IMs at the predefined levels (poes)\n",
        "meanLst, modeLst = disagg_MReps(Mbin, dbin,T_star, path_dis, output_dir=fig_dir, \n",
        "                                          n_rows=1, filename=\"Mag_Dist_Eps\")  # mean and mode scenarios from disaggregation (M, R and epsilon) --- slow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av22TIDPmyMf"
      },
      "source": [
        "# Creating the target\n",
        "The next step is to create the target spectra using the GMPE with the values obtained from the disaggregation analysis at the intensity level (IML) of choice.\n",
        "\n",
        "First we get the required values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py34MWD7mf_T",
        "outputId": "5c4c9283-a0a3-40a6-b082-a33ccc31327c"
      },
      "outputs": [],
      "source": [
        "All_CS = []\n",
        "j=nIM-1\n",
        "print(\"IM level:\", str(nIM))\n",
        "# Initialize the CS class\n",
        "CS1 = CS(mat_dir, T_star=T_star, gmpe=\"BooreAtkinson2008\", pInfo=1)\n",
        "mag = meanLst[j][0]\n",
        "rjb = meanLst[j][1]\n",
        "eps = meanLst[j][2]  # not used here\n",
        "im_T_star = imls[0][j]\n",
        "print(\"Poe is:\", 100*poes[j], \"% in 50 years.\", \"Mean Magnitude and Rjb are:\", np.round(mag, 2), np.round(rjb, 2))\n",
        "print(\"IM at the level\", str(nIM), \"is:\", np.round(im_T_star, 3))\n",
        "SOF, W, dip, Ztor, Rrup, Rx, Ryo, Z1 = CS1.getUnknown_params(M=mag, Fhw=Fhw, rake=rake, Rjb=rjb, Vs30=Vs30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jivrfavWnIv-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Now, we create the target spectrum using the required data for the GMPE and values from disaggregation. \n",
        "\n",
        "\n",
        "This will allow us to create our mean conditional target spectrum with:\n",
        "\n",
        "\n",
        "\n",
        " $\\mu_{lnSa(T_i)|lnSa(T*)} = \\mu_{lnSa}(M,R,T_i)+\\rho(T_i,T*)\\epsilon(T*)\\sigma_{lnSa}(T_i)$\n",
        "\n",
        "\n",
        "\n",
        " Where  $\\mu_{lnSa}(M,R,T_i)$ is the unconditional mean spectrum, computed simply through the GMPE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Where the correlation between periods  $\\rho(T_i,T_j)$ is computed following Baker and Jayaram, 2008 (https://journals.sagepub.com/doi/pdf/10.1193/1.2857544)\n",
        "\n",
        "\n",
        "Finally, **for the conditional dispersion** at each period, the calculations are done with the following equations, also found in the script:\n",
        "\n",
        "Where this dispersion is found in the diagonal of the conditional covariance matrix is found as:\n",
        "\n",
        "\n",
        "$\\Sigma_{cond} = \\Sigma -\\frac{\\Sigma_{cross}\\Sigma_{cross}^T} {\\sigma_{lnSa}(M,R,T^*)^2}$\n",
        "\n",
        "Where $\\Sigma$ is the covariance matrix:\n",
        "\n",
        "$\\Sigma = \\left[\\begin{matrix}\n",
        "\\sigma^2_{T_i} & \\sigma_{T_i,T_j}\\\\\n",
        "\\sigma_{T_j,T_i} & \\sigma^2_{T_j}\n",
        "\\end{matrix}\\right]$\n",
        "\n",
        "And $\\Sigma_{cross}$ is a matrix of covariance between the periods $T^*, T_i$ and $T_j$\n",
        "\n",
        "$\\Sigma_{cross} = \\left[\\begin{matrix}\n",
        "\\sigma_{T_i,T^*}\\\\\n",
        "\\sigma_{T^*,T_j}\n",
        "\\end{matrix}\\right]$\n",
        "\n",
        "Where the terms between periods $T_i$ and $T_j$ are computed as:\n",
        "\n",
        "$\\sigma_{T_i,T,j}=\\rho(T_i,T_j)\\sigma_{lnSa}\\sigma_{lnSa}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "IXFnbYPNnEjM",
        "outputId": "41c1c8cf-0817-4067-d230-645967768bf3"
      },
      "outputs": [],
      "source": [
        "# Create the target spectra\n",
        "CS1.create(site_param={\"vs30\": Vs30},\n",
        "                                rup_param={\"rake\": rake, \"mag\": [mag]},\n",
        "                                dist_param={\"rjb\": [rjb], \"rrup\": Rrup, \"rx\": Rx, \"ry0\": Ryo}, Hcont=None, T_Tgt_range=T_target, im_T_star=im_T_star,\n",
        "                                epsilon=None, cond=1, useVar=1, corr_func=\"baker_jayaram\")\n",
        "print(\"Target distribution is defined\")\n",
        "\n",
        "CS1.plot_Target(j, save=0, show=1, name_dir=fig_dir)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mP18R5M3nM1l"
      },
      "source": [
        "# Ground motion selection\n",
        "This next step is where the simulations are performed, obtaining different spectral values for different records.\n",
        "\n",
        "(See: https://journals.sagepub.com/doi/pdf/10.1193/1.3608002)\n",
        "\n",
        "The first step is to probabilistically simulate a set of response spectra that comply with the target\"s mean and variance through Monte Carlo sampling;\n",
        "\n",
        "\n",
        "Then, for each simulated response spectrum, a ground motion with a similar response spectrum is then selected, and given that the Monte Carlo simulations have the target\"s mean and variance, it is expected that the selected GM will have it as well.\n",
        "\n",
        "### Greedy optimization\n",
        "\n",
        "These records are then evaluated and optimized in terms of $\\mu$lnSa and $\\sigma$lnSa through the greedy optimization process.\n",
        "The error is computed through: \n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\text{SSE } & = \\sum_{j=1}^p\\left[ \\left( \\hat{m}_{lnSa(T_j)}-\\mu^{(t)}_{lnSa(T_j)} \\right)^2+w\\left( \\hat{s}_{lnSa(T_j)}-\\sigma^{(t)}_{lnSa(T_j)} \\right)^2\\right]. \\\\[1em]\n",
        "\\\n",
        "\\end{align}\n",
        "\n",
        "Where $\\hat{m}_{lnSa(T_j)}$ and $\\hat{s}_{lnSa(T_j)}$ are the sample\"s mean and standard deviation, and $\\mu_{lnSa(T_j)}$ and $\\sigma_{lnSa(T_j)}$ are the target\"s mean and standard deviation, respectively.\n",
        "\n",
        "In the end the records producing the lowest SSE are chosen for the final selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "X9VYaBalnQ48",
        "outputId": "bd274678-7e25-444a-cf39-935dfeb32472"
      },
      "outputs": [],
      "source": [
        "# Select ground motion records\n",
        "CS1.select(nGM=nGM, selection=2, Sa_def=\"RotD50\", isScaled=1, maxScale=maxSF, minScale=minSF, Mw_lim=[4, 8],\n",
        "            DB_lim=[\"Ridge\",\"NGA\",\"GNS\"], Vs30_lim=Vs30_lims, Rjb_lim=None, fault_lim=None, freefield=True, nTrials=20, weights=[1, 2, 0.3], seedValue=0, nLoop=20, penalty=1, tol=10)\n",
        "CS1.plot_sel((j), save=1, show=1, initial=1, name_dir=fig_dir)  \n",
        "All_CS.append(CS1)\n",
        "\n",
        "\n",
        "print(\"Records selected!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peirHWfJn7Z9"
      },
      "source": [
        "# Exporting data\n",
        "Now that the CS algorithm is done, we have obtained our record set, this set contains information about the records, such as the event name, network and station (can be downloaded from the ESM database - https://esm-db.eu/#/home) or alternatively, the file name (if all the database is previously downloaded), scaling factors, ground motion data and causative parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B-UbEwRV0bm-",
        "outputId": "8e4664fc-b88b-4106-f71b-b1ba2151a258"
      },
      "outputs": [],
      "source": [
        "from sys import intern\n",
        "resdata={\"Network\":All_CS[0].eq_ID,\"Station\":All_CS[0].eq_ID,\"Event\":All_CS[0].eq_ID,\"SF\":All_CS[0].rec_scale,\"dt\":All_CS[0].dt,\"npts\":All_CS[0].nstp,\"Mw\":All_CS[0].rec_Mw,\"R\":All_CS[0].rec_Rjb,\"Vs30\":All_CS[0].rec_Vs30,\"Fname1\":All_CS[0].rec_h1,\"Fname2\":All_CS[0].rec_h2,\"url\":All_CS[0].eq_ID}\n",
        "import pandas as pd \n",
        "ResDF = pd.DataFrame(data=resdata)\n",
        "\n",
        "# get event names, network and station for ESM search\n",
        "for inn in range(nGM):\n",
        "  s = ResDF.Fname1[inn]\n",
        "  start = s.find(\".D.\") + len(\".D.\")\n",
        "  end = s.find(\".ACC.\")\n",
        "  EvenID = s[start:end]\n",
        "  partitioned_string = s.partition(\".\")\n",
        "  ResDF.Network[inn]=partitioned_string[0]\n",
        "  ResDF.Event[inn]=EvenID\n",
        "  start = s.find(partitioned_string[0]) + len(partitioned_string[0])+1\n",
        "  end1 = s.find(\"..\")\n",
        "  end2 =s.find(\".00.\")\n",
        "  end = max(end1,end2)\n",
        "  Statr = s[start:end]\n",
        "  ResDF.Station[inn]=Statr\n",
        "  try:\n",
        "    urli=\"https://esm-db.eu/#/waveform/\"+ResDF.Network[inn]+\"/\"+ResDF.Station[inn]+\"/00/\"+EvenID+\"/HG\"\n",
        "  except:\n",
        "    urli=\"error\"\n",
        "  ResDF.url[inn]=urli\n",
        "# export table\n",
        "ResDF.to_csv(output_dir+\"/RecSelection_IM_\"+str(nIM)+\".csv\")\n",
        "ResDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st0QQ-BQlHrP"
      },
      "source": [
        "# Selected records\n",
        "\n",
        "Now with everything done, the records can be processed in many ways and finally downloaded for time history analysis..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "RIB7nbBkdiiF",
        "outputId": "0b1107a3-5203-4fca-aae1-3f9ead616683"
      },
      "outputs": [],
      "source": [
        "for k in range(nGM):\n",
        "  plt.loglog(All_CS[0].T,np.exp(All_CS[0].rec_spec[k,:]),\"silver\")\n",
        "#plt.loglog(All_CS[0].T,np.exp(All_CS[0].mu_ln),\"r\"); # Target\n",
        "plt.xlabel(\"Period [s]\",fontsize=14)\n",
        "plt.ylabel(\"Spectral acceleration [g]\",fontsize=14)\n",
        "plt.xlim(All_CS[0].T[0],All_CS[0].T[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6esNzF-nwUs"
      },
      "source": [
        "See the selected records, relevant data and download at the ESM website.\n",
        "\n",
        "Ideally, it is better to have the full DB files so that they can be selected, processed and used automatically for the relevant analyses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYYc2dPRl5hY",
        "outputId": "c3d26e88-8379-4ead-d6b5-b5399520ce8a"
      },
      "outputs": [],
      "source": [
        "for zz in ResDF.url:\n",
        "  print(zz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO_eEDP4xNcD"
      },
      "source": [
        "More information on CS can be found [here](https://www.youtube.com/watch?v=1B6d9rrMPu0) (video by Jack Baker on CMS)\n",
        "\n",
        "If you are more familiar with MATLAB, we have developed record selection scripts based on the ones by Jack Baker (https://github.com/bakerjw/CS_Selection) originally developed for NGA, modified for the ESM database."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SummerSchool.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b2e652f635080af47a587503e30de6976439f49ada01b3349f0f0746ac93a74c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
